{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분류\n",
    "강아지냐 고양이냐\n",
    "\n",
    "classification 분리하는 선(경계) 하나 긋는것 \n",
    "\n",
    "logistic regression \n",
    "svm\n",
    "decision tree\n",
    "random forest\n",
    "\n",
    "evaluation\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris=load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로지스틱 회귀(Logistic Regeission) \n",
    "가볍게 쓰기 좋은\n",
    "odds를 그대로 사용하지 말고 log를 취해 사용하면 0을 기준으로 상호 대칭적이며\n",
    "계산을 수월하게 할 수 있도록 변경해준다.\n",
    "기존의 선형회귀식에서 y위치에 log Odds를 적용하면 된다\n",
    "Odds=p/1-p (p:어떤 일이 발생할 확률)\n",
    "\n",
    "이를 y에 대해 정리하면 그 유명한sigmoid 식이 된다.로지스틱은 맞다, 아니다 로 나눠지므로 잔차를 구할수 없다.\n",
    "\n",
    "로지스틱 회귀는 이진분류 모델인데 어떻게 여러개의 클래스로 분류할수 있을까?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(data,label,test_size=0.2,shuffle=True, sttatify=label,random_state=2019)\n",
    "\n",
    "1.모델불러오기 및 정의하기\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression\n",
    "\n",
    "2.모델학습하기(훈련데이터)\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "3.결과 예측하기(테스트데이터) & 확률보기\n",
    "y_pred=lr.predict(X_test)\n",
    "\n",
    "4.확률보기\n",
    "lr.predict_prob(X_test)\n",
    "\n",
    "5.결과살펴보기\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('로지스틱 회귀, 정확도: {:.2f}%'.format(accuracy_score(y_test,y_pred)*100))\n",
    "\n",
    "로지스틸 회귀모델의 계수w 절편b 살펴보기\n",
    "어떤 변수에 얼마만큼의 가중치(기울기)가 할당되고, 절편값은 얼마나 할당되는지 살펴볼수 있다.\n",
    "3개의 멀티 클래스 분류이므로 One-vs-Rest, 3개의 회귀식을 가지고 있다.\n",
    "\n",
    "print('로지스틱 회귀, 계수(w):{}, 절편(b): {}'.format(lr.coef_,lr.intercept_))\n",
    "3X4출력, 절편3개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 서포트벡터머신\n",
    "support vector machine은 주어진 데이터를 바탕으로 해서 두 카테고리(이진분류의 경우) 사이의 간경(margine 마진)을 최대화하는 데이터 포인트(support vector 서포트벡터)를 찾아내고, 그 서포트 벡터에 수직인 경계를 통해 데이터를 분류하는 알고리즘\n",
    "\n",
    "cost:soft or hard  C= \n",
    "soft :위험을 감수하면서 자르는거 \n",
    "hard :위험을 감수하지 않고 절대적으로 자르는 것(2차원으로는 절대로 나누지 못하는 게 있다.)\n",
    "\n",
    "참고)kernal:kernal trick 에서 2차원으로 나누지 못하는 것을 고차원으로 보내서 나누는 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "왜 마진을 최대화할까요?\n",
    "경험적 위험 최소화\n",
    "경험적 위험 최소화-훈련데이터에 대한 위험을 최소화\n",
    "구조적 위험 최소화-관찰하지 않는 (unseen)데이터에 대해서도 위험을 최소화\n",
    "\n",
    "단점-복잡도가 높다 시간이 오래걸린다\n",
    "장점-데이터가 충분하다는 가정하에 튜닝을 할 필요가 없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.모델불러오기 및 정의하기\n",
    "from sklearn.svm import SVC\n",
    "svc=SVC()\n",
    "\n",
    "2.모델학습하기(훈련데이터)\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "3.결과 예측하기(테스트데이터) & 확률보기\n",
    "y_pred=svc.predict(X_test)\n",
    "\n",
    "4.확률보기\n",
    "lr.predict_prob(X_test)\n",
    "\n",
    "5.결과살펴보기\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('서포트벡터머신, 정확도: {:.2f}%'.format(accuracy_score(y_test,y_pred)*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결정트리()\n",
    "불순도나 엔트로피를 줄이는 방향으로 자르는것 \n",
    "예)남자나 여자냐 \n",
    "greedy 알고리즘은 뒤로 되돌리지 않는다.빠르다.\n",
    "데이터 전처리가 덜필요하다. \n",
    "\n",
    "(스케일링 할 필요가 없다. 값으로 자르기 때문에??)\n",
    "\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt=DecisionTreeClassifier()\n",
    "\n",
    "...\n",
    "feature importance \n",
    "트리기반 모델은 트리를 분기하는 과정에서 어떤 변수가 모델을 \n",
    "생성하는 데 중요한지에 대한 변수 중요도를 살펴볼 수 있다.\n",
    "\n",
    "feature_importance=pd.DataFram(dt.feature_importance_.reshape((1,-1)),columns=columns,index['feature_importance'])\n",
    "feature_importance\n",
    "\n",
    "(여기서 열에 -1이 오면 행에 따라 가변적으로 정해주라는 의미다)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
