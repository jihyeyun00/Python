{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scikit\n",
    "\n",
    "\n",
    "machine learning package\n",
    "deep learning 요소가 조금 들어가 있음\n",
    "GPU (고속 분산처리)는 안함 - 잘하는 것에 집중\n",
    "가장 많이 쓰임\n",
    "한사람이 관리 → interface의 일관성 있음 (시간이 지나 필요없는 건 deprecate 시켜버림) → 사용하기 쉬움\n",
    "pandas와 통일시키려는 목적이 있음\n",
    "estimator(추정기) transformer(전처리된 데이터로 변환) → fit, transform, predict\n",
    "model을 만드는 게 아니라, 있는 model의 parameter를 추정\n",
    "tensorflow는 나만의 model을 만들 수 있음 (복잡한 문제를 해결할 때 사용)\n",
    "\n",
    "\n",
    "-----------------------------------------------------------------------\n",
    "\n",
    "scikit은 문제해결을 위한 도구\n",
    "\n",
    "\n",
    "사용하는 알고리즘 3가지\n",
    "simulation\n",
    "optimization (최적화)\n",
    "data mining (규칙탐구 _ 데이터 속에서 규칙을 발견 → 의사결정을 위해)\n",
    "\t\n",
    "\n",
    "일반화된 문제 해결 (not 특수한 문제) (특수한 문제해결 = 과대적합, overfitting)\n",
    "\n",
    "과대적합의 문제 : 일반 데이터(학습되지 않은 데이터)의 분산이 커짐\n",
    "bias variance trade off (bias는 타겟에서 멀어진 것, variance는 각각의 오차)\n",
    "\n",
    "\n",
    "scikit이 하는 일\n",
    "\n",
    "classification (분류) → 내일\n",
    "regression (예측) → 오늘 수업내용\n",
    "clustering (군집)\n",
    "\n",
    "\n",
    "model 의 종류\n",
    "\n",
    "정보 기반 _ Decision Tree, Random Forest, ADA boost, gradient boost, XG boost (GPU, 다중언어 지원), ensemble/stack model\n",
    "확률 기반 _ Naive Bayes (text mining) → 나중에 RNN과 만남, 히든 마르코프 모델, CRM 모델,… \n",
    "유사도 기반 _ KNN, K-means, 추천\n",
    "오차 기반 _ ANN, SVM (support vector machine)\n",
    "\n",
    "\n",
    "오늘은 scikit 명령어 익히기 & regression\n",
    "내일은 정보기반\n",
    "그담날은 유사도기반\n",
    "그담날은 오차기반\n",
    "\n",
    "\n",
    "Data\n",
    "\n",
    "\n",
    "\n",
    "좋은 데이터는? “대표성이 있어야 함”\n",
    "\n",
    "\n",
    "\n",
    "feature engineering\n",
    "\n",
    "\n",
    "\n",
    "전처리 (결측치, 이상치, 범주화, 정규화)\n",
    "\t-결측치 처리 방법 중 중요한 것 : 특성유사도 knn 기반 채워놓기\n",
    "\n",
    "\t-이상치 처리 IQR * 1.5 (2.65) / 2배수에 95%, 3배수에 99%\n",
    "\n",
    "\t-범주화 cut, qcut(일정한 사이즈/개수로), get dummies(원핫인코딩)\n",
    "\n",
    "\t-정규화 min-max / z-점수 / robust / normalization\n",
    "\n",
    "변형 (transformation)\n",
    "\t-select / filter / summarize / arrange\n",
    "\n",
    "\t→ scikit에서 엄청난 양의 함수들을 지원함\n",
    "\n",
    "model select\n",
    "variable select (변수 중요도)\n",
    "특성 추출 (feature extraction)\n",
    "\n",
    "\n",
    "model selection\n",
    "\n",
    "\n",
    "\n",
    "training data / test data\n",
    "\n",
    "training data만 가지고 model 만들면 과대적합, 특화되어 있는 모델 (일반화되어 있지 않음)\n",
    "\n",
    "test data로 확인해야 함\n",
    "\n",
    "test data에도 적합되어버림\n",
    "\n",
    "그래서 validation data 검증데이터가 필요함 \n",
    "\n",
    "k-fold 방식으로 진행\n",
    "\n",
    "\n",
    "\n",
    "variable selection\n",
    "\n",
    "\n",
    "\n",
    "이전에는 변수 중요도를 알기 위해서 상관분석을 진행했었음\n",
    "\n",
    "분산이 큰 변수가 중요한 변수\n",
    "\n",
    "다중공선성, 자기상관성의 문제\n",
    "\n",
    "다중공선성 데이터 해결 (@scikit) → Lasso, Ridge, Elastic Net : regulization (규제) →  과적합 방지!\n",
    "\n",
    "\n",
    "\n",
    "feature extraction\n",
    "\n",
    "\n",
    "\n",
    "에러, 오류가 있는 데이터를 걸러내는 역할\n",
    "\n",
    "FA (factor analysis, 요인분석) / PCA (principal component analysis, 주성분분석) / MDS(Multi dimension scaling, 다차원 척도법)\n",
    "\n",
    "\n",
    "\n",
    "평가\n",
    "\n",
    "\n",
    "\n",
    "classification ) 정분류율 / 정밀도 / 재현율 / 특이도\n",
    "\n",
    "regression ) 상관계수, MSE(mean square error _ domain knowledge를 아는 사람이 판단할 수 있음)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
