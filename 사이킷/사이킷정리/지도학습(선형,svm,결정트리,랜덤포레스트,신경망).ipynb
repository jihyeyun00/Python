{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "boston=load_boston()\n",
    "\n",
    "습관적으로 할것!\n",
    "print(boston.DESCR)\n",
    "data=boston.data\n",
    "label=boston.target\n",
    "columns=boston.feature_names\n",
    "\n",
    "data=pd.DataFrame(data,columns=columns)\n",
    "data.head()\n",
    "\n",
    "data.shape\n",
    "\n",
    "data.describe()\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선형회귀(LinearRegression)\n",
    "(지도학습으로 레이블이 주어졌을 때)\n",
    "참값(yi)와 회귀모델이 출력한y^ 사이의 잔차(error)의 제곱의 합을 최소화하는 w(계수)를 구하는 것이 목적 =least square 최소제곱법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.모델 불러오기 및 정의하기\n",
    "sim_lr=LinearRegression()\n",
    "\n",
    "2.모델 학습하기(훈련데이터)\n",
    "sim_lr.fit(X_train,y_train)\n",
    "\n",
    "3.결과예측하기(테스트데이터)\n",
    "y_pred=sim_lr.predict(X_test)\n",
    "\n",
    "4.결과살펴보기\n",
    "일반적으로 선형회귀 R2(제곱)을 평가척도로 사용한다\n",
    "R2(제곱)값이 1에 가까울 수록 회귀모델이 데이터를 잘 표현한다는 것을 의미한다.\n",
    "from sklearn.metrics import r2_score\n",
    "print('단순선형회귀, R2:{:.4f}'.format(r2_score(y_test,y_pred)))\n",
    "\n",
    "5.그래프그리기 'rm'은 컬럼이름\n",
    "line_x=np.linspace(np.min(X_test['RM']), np.max(X_test['RM']),10)\n",
    "line_y=sim_lr.predict(line_x.reshape((-1,1)))\n",
    "\n",
    "plt.scatter(X_test['RM'],y_test, c='black')\n",
    "plt.plot(line_x,line_y,c='red')\n",
    "plt.legend(['regression line','test data sample'],loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "다중회귀\n",
    "\n",
    "http://hleecaster.com/ml-multiple-linear-regression-example/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결정트리\n",
    "트리모델을 데이터의 불순도(impurity,Entropy)를 최소화하는 방향으로 트리를 분기하여 모델을 생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "지도학습으로 레이블이 있는 모델\n",
    "\n",
    "1.모델불러오기 및 정의하기\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt_regr=DecisionTreeRegressor(max_depth=5)\n",
    "\n",
    "2.모델학습하기(훈련데이터)\n",
    "dt_regr.fit(X_train,y_train)\n",
    "\n",
    "3.결과 예측하기(테스트데이터)\n",
    "y_pred=dt_regr.predict(X_test)\n",
    "\n",
    "4.결과 살펴보기\n",
    "일반적으로 선형회귀R2(제곱)을 평가척도로 사용 1에 가까울수록 모델일 데이터를 잘 표현한다는 \n",
    "print('다중결정트리, R2:{:.4f}'.format(r2_score(y_test,y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랜덤포레스트(Random Forest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf=RandomForestRegressor(max_depth=5)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred=rf.predict(x_test)\n",
    "print('단순 결정 트리 회귀, R2: {:.4f}'.format(r2_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 서포트 벡터 머신(support vector machine regressor)\n",
    "서포트 벡터 머신의 기본개념은 결정 경계와 데이터 샘플의 거리(margine)을 최대화 하는 방식으로 모델을 조정한다.\n",
    "서포트 벡터 머신회귀모델을 sklearn 의 svm패키지에 있다.\n",
    "\n",
    "kenel('linear','poly','rbf','sigmoid')펑션에 따라 영향을 많이 받음 폴리를 쓰게되면 시간이 오래걸림\n",
    "degree는 차원, gamma는 얼마나 선을 구불구불하게 할건가, C=1.0 에러를 감수하며 좋은 선을 만들어 낼건가 일반적으로 1.0을 씀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.모델 불러오기 및 정의하기\n",
    "from sklearn.svm import SVR\n",
    "svm_regr=SVR()\n",
    "\n",
    "2.모델학습하기(훈련데이터)\n",
    "svm_regr.fit(X_train,y_train)\n",
    "\n",
    "3.결과 예측하기(테스트데이터)\n",
    "y_pred=svm_regr.predict(X_test)\n",
    "\n",
    "4.결과살펴보기\n",
    "R2로 평가확인\n",
    "print('단순서포트벡터머신회귀, R2:{:.4f}'.format(r2_score(y_test,y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks\n",
    "Multi layer perception regressor\n",
    "\n",
    "딥러닝의 기본모델일 뉴럴네트워크를 기반으로 한 회귀모델\n",
    "기본적으로 MLP라 하면 입력층-은닉층-출력층 3개로 이루어진 뉴럴네트워크를 말한다.\n",
    "\n",
    "hidden_Layer_size=(100,50,10,10...) 많으면 많을 수록 복잡해진다.\n",
    "activation='relu','linear','sigmoid','tanh'\n",
    "solver='sgd','lbfgs''adam' (일반적으로 아담을 제일많이 씀)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.모델 불러오기 및 정의하기\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp_regr=MLPRegressor(hidden_layer_sizes=(100,50,10),activation='tanh',solver='sgd',radom state=2019)\n",
    "\n",
    "2.모델학습하기(훈련데이터)\n",
    "mlp_regr.fit(X_train,y_train)\n",
    "\n",
    "3.결과 예측하기(테스트데이터)\n",
    "y_pred=mlp_regr.predict(X_test)\n",
    "\n",
    "4.결과살펴보기\n",
    "R2로 평가확인\n",
    "print('단순mlp회귀, R2:{:.4f}'.format(r2_score(y_test,y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2(알스퀘어)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
