{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "dataset = numpy.loadtxt(\"pima.data\", delimiter=\",\") #원랜 csv인데 없당\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:, 8]\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid,\n",
    "                   n_jobs=-1)\n",
    "grid_result = grid.fit(X, Y)\n",
    "print(\"최적스코어: %f   사용한 파라미터조합 : %s\" % (grid_result.best_score_,\n",
    "                                      grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  문제\n",
    "# 가중치 초기화 매개변수를 넣고 (kernel_initializer)\n",
    "# ['uniform', 'lecun_uniform','normal','zero','glorot_normal','glorot_uniform','he_normal','he_uniform']\n",
    "# 최적의 가중치 초기화 파라미터 선정\n",
    "\n",
    "# dense 1 : activation 함수를 달아주고\n",
    "# ['softmax', 'softplus', 'softsign','relu','tanh','sigmoid','hard_sigmoid','linear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 아웃없는거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the weight initialization\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(init_mode='uniform',optimizer='relu'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #8 12  12 1\n",
    "    model.add(Dense(12, input_dim=8, kernel_initializer=init_mode, activation=optimizer))\n",
    "    #model.add(Dense(6)) 내가 넣은거\n",
    "    model.add(Dense(1))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) #categorical_:3개 이상 y값이 몇개냐에 따라서 2개냐 2개 이상이냐...\n",
    "       return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load dataset\n",
    "dataset = numpy.loadtxt(\"pima.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=1)\n",
    "# define the grid search parameters\n",
    "init_mode = ['uniform', 'lecun_uniform','normal','zero','glorot_normal','glorot_uniform','he_normal','he_uniform']\n",
    "optimizer = ['softmax', 'softplus', 'softsign','relu','tanh','sigmoid','hard_sigmoid','linear']\n",
    "param_grid = dict(init_mode=init_mode,optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop out 있는거 :계산을 줄인다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the weight initialization\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping\n",
    "stopper = EarlyStopping(monitor='var_accuracy', patience=3, verbose=1) #verbose 출력여부결정\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(init_mode='uniform',optimizer='relu',dropout_rate=0.1):\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, kernel_initializer=init_mode, activation=optimizer))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load dataset\n",
    "dataset = numpy.loadtxt(\"pima.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "# Earlystopping\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=1)\n",
    "# define the grid search parameters\n",
    "dropout_rate=[0.1,0.2,0.3] # ,0.4,0.5,0.6,0.7,0.8,0.9\n",
    "init_mode = ['uniform', 'lecun_uniform']# ,'normal','zero','glorot_normal','glorot_uniform','he_normal','he_uniform'\n",
    "optimizer = ['softmax','relu'] #, 'softplus', 'softsign','tanh','sigmoid','hard_sigmoid','linear'\n",
    "param_grid = dict(init_mode=init_mode,optimizer=optimizer,dropout_rate=dropout_rate)\n",
    "fit_params = dict(callbacks=[stopper])\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "# 변동 매개변수\n",
    "grid_result = grid.fit(X, Y, **fit_params)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dataframe = pd.read_csv(\"housing.csv\", delim_whitespace=True, header=None) \n",
    "dataset = dataframe.values #value r값만 넣어주면 넘파이로 변환!\n",
    "X = dataset[:,0:13]\n",
    "Y = dataset[:,13]\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100,batch_size=5,verbose=1)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "result = cross_val_score(estimator,X,Y,cv=kfold)\n",
    "print(\"Result: %.2f (%.2f) MSE\" % (result.mean(),result.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = estimator.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(pre, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "estimaters = []\n",
    "estimaters.append(('standardize', StandardScaler())) #standardize 이름지정,\n",
    "estimaters.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50,batch_size=5,verbose=0))) #mlp 이름지정\n",
    "pipeline = Pipeline(estimaters)\n",
    "kfold = KFold(n_splits =10, random_state=seed)\n",
    "result =cross_val_score(pipeline,X,Y,cv=kfold) #x에 적용StandardScaler ,Y 에 적용KerasRegressor ,cv=kfold 가 검증\n",
    "print(\"Standardized : %.2f (%.2f) MSE \"% (result.mean(), result.std()))\n",
    "pipeline.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pipeline.predict(X)\n",
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.corrcoef(res, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, kernel_initializer='normal',activation='relu'))\n",
    "    model.add(Dense(6, kernel_initializer='normal',activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wider_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "estimaters.append(('standardize', StandardScaler()))\n",
    "estimaters.append(('mlp', KerasRegressor(build_fn=larger_model, epochs = 100, batch_size=5, verbose=1)))\n",
    "pipeline = Pipeline(estimaters)\n",
    "kfold = KFold(n_splits =10, random_state=seed)\n",
    "result =cross_val_score(pipeline,X,Y,cv=kfold)\n",
    "print(\"Standardized : %.2f (%.2f) MSE \"% (result.mean(), result.std()))\n",
    "pipeline.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = pipeline.predict(X)\n",
    "np.corrcoef(predict, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "estimaters.append(('standardize', StandardScaler()))\n",
    "estimaters.append(('mlp', KerasRegressor(build_fn=wider_model, epochs = 100, batch_size=5, verbose=1)))\n",
    "pipeline2 = Pipeline(estimaters)\n",
    "kfold = KFold(n_splits =10, random_state=seed)\n",
    "result =cross_val_score(pipeline,X,Y,cv=kfold)\n",
    "print(\"Standardized : %.2f (%.2f) MSE \"% (result.mean(), result.std()))\n",
    "pipeline2.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict2 = pipeline2.predict(X)\n",
    "np.corrcoef(predict2, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숙제 \n",
    "- iris.csv 데이터를 로딩한 다음\n",
    "- 분류을 구성하시오\n",
    "- parameter tuning을 구현하시오 (Pipe line 사용도 함께)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
