{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "기본 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-1-f36586120ab2>:46: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-1-f36586120ab2>:48: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\jhjhy\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\jhjhy\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:459: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000235E36F6988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000235E36F6988>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000235E36F6988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000235E36F6988>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000235E36F6988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000235E36F6988>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000235E36F6988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000235E36F6988>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#def reset_graph(seed=42):\n",
    "#    reset_default_graph()\n",
    "#    tf.set_random_seed(seed)\n",
    "#    np.random.seed(seed)\n",
    "\n",
    "#tf.reset_default_graph() #그래프 초기화 (변수 생성)\n",
    "#\n",
    "#n_inputs=3 #입력데이터\n",
    "#n_neurons=5 #셀의 가중치 사이즈\n",
    "#\n",
    "#X0=tf.placeholder(tf.float32,[None,n_inputs]) #4x3 으로 들어옴\n",
    "#X1=tf.placeholder(tf.float32,[None,n_inputs]) #4x3 으로 \n",
    "#\n",
    "##[0,1,2] 하나의 셀로 입력\n",
    "##FFNN(말단 데이터 하나가)\n",
    "##(num_units=n_neurons) :가중치 사이즈=>특성을 찾아내는 것\n",
    "#basic_cell=tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)  #사이즈를 5개로 찾아내겠다\n",
    "#\n",
    "##static_rnn :rnn 네트워크 :4개의 셀이 연결되면서 메모리 확보\n",
    "#output_seqs,states=tf.contrib.rnn.static_rnn(basic_cell,[X0,X1],dtype=tf.float32) #2 4 3  #2는 배치사이즈 x 셀 수 x 뉴런수\n",
    "#Y0,Y1=output_seqs\n",
    "#\n",
    "##출력, 다음 셀로 연결되는 값:마지막 state값(수평으로 연결)\n",
    "#init=tf.global_variables_initializer()\n",
    "#X0_batch=np.array([0,1,2],[3,4,5],[6,7,8],[9,0,1])\n",
    "#X1_batch=np.array([9,8,7],[0,0,0],[6,5,4],[3,2,1])\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# def reset_graph(seed=42):\n",
    "#     tf.reset_default_graph()\n",
    "#     tf.set_random_seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "tf.reset_default_graph() # 그래프 초기화(변수 생성)\n",
    "n_inputs = 3 # 입력 데이터\n",
    "n_neurons = 5 # 셀의 가중치 사이즈\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs]) # 4x3\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs]) # 4x3\n",
    "# [0,1,2] 사이즈가 하나의 셀로 입력\n",
    "# FFNN(Feed Forward Neural Network)\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "# static_rnn : RNN Network [4개의 셀이 연결되면서 메모리 확보]\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, [X0, X1], dtype=tf.float32) # 2x4x3 [배치 사이즈*셀 수*뉴런 수]\n",
    "Y0, Y1 = output_seqs\n",
    "init = tf.global_variables_initializer() # 출력, 다음 셀로 전달되는 값: 마지막 states 값(수평으로 셀을 연결)\n",
    "X0_batch = np.array([[0,1,2],[3,4,5],[6,7,8],[9,0,1]])\n",
    "X1_batch = np.array([[9,8,7],[0,0,0],[6,5,4],[3,2,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처음 데이터 특성:  [[-0.93172103  0.8611625   0.4901676  -0.84947175 -0.38926083]\n",
      " [-0.99980164  0.996971    0.8299809  -0.8657474   0.854739  ]\n",
      " [-0.9999995   0.9999383   0.9507826  -0.88037705  0.99462146]\n",
      " [-0.4373169  -0.79141515  0.9937681   0.99993294  0.9998212 ]] 차수:  (4, 5)\n",
      "두번째 데이터 특성:  [[-0.9999953   0.99992454  0.7928492   0.8861348   0.9998628 ]\n",
      " [ 0.2832867   0.73218375 -0.50428265  0.4349015  -0.5756295 ]\n",
      " [-0.9993412   0.9983429   0.13845792  0.92875814  0.99566257]\n",
      " [-0.9784409   0.04489376 -0.3344527   0.9089518   0.8869909 ]] 차수:  (4, 5)\n"
     ]
    }
   ],
   "source": [
    "#with tf.Session() as sess:\n",
    "#    init.run()\n",
    "#    Y0_val,Y1_val=sess.run([Y0,Y1],feed_dict={X0:X0_batch,X1:X1_batch})\n",
    "#print('처음 데이터 특성:',Y0_val,\"차수:\",Y0_val.shape)\n",
    "#print('두번째데이터 특성:',Y1_val,\"차수:\",Y1_val.shape)\n",
    "#\n",
    "##4x3 =>4x5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0,Y1], feed_dict={X0: X0_batch, X1: X1_batch})\n",
    "\n",
    "print(\"처음 데이터 특성: \", Y0_val, \"차수: \",Y0_val.shape)   # 4*5 : cell이 4개, 특징 5개\n",
    "print(\"두번째 데이터 특성: \", Y1_val, \"차수: \",Y1_val.shape) # 4*5\n",
    "# 4*3 -> 4*5\n",
    "# 셀이 가지고 있는 가중치 사이즈는? : 3*5 : 3개가 들어와서 5개로 나갔으니까..... : 4*3 -> 4*5에서 끝 부분들.. 3*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#셀이 가지고 있는 가중치 사이즈는  3x 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-0fa847dfb769>:51: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001C15EA04808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001C15EA04808>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001C15EA04808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001C15EA04808>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-5-0fa847dfb769>:58: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001C15EEBAD88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001C15EEBAD88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001C15EEBAD88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001C15EEBAD88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "#def reset_graph(seed=42):\n",
    "#    reset_default_graph()\n",
    "#    tf.set_random_seed(seed)\n",
    "#    np.random.seed(seed)\n",
    "#\n",
    "#tf.rest_default \n",
    "#n_steps=28\n",
    "#n_inputs=28\n",
    "#n_neurons=150\n",
    "#n_outputs=10\n",
    "#learning_rate=0.001\n",
    "#\n",
    "#X=tf.placeholder(tf.float32,[None,n_steps,n_inputs])\n",
    "#Y=tf.placeholder(tf.int32,[None])\n",
    "#\n",
    "#basic_cell=tf.contrib.rnn.basicRNNCell(num_units=n_neurons)\n",
    "#outputs,states=tf.nn.dynamic_rnn(basic_cell,X,dtype=tf.float32)\n",
    "#logits=tf.layers.dense(states,n_outputs)\n",
    "#xentropy=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "#\n",
    "#loss=tf.reduce_mean(xentropy)\n",
    "#optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "#training_op=optimizer.minimize(loss)\n",
    "#\n",
    "#correct=tf.nn.in_top.k(logits,y,1)\n",
    "#accuracy=tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "#init=tf.global_varables_initializer()\n",
    "\n",
    "\n",
    "#이미지 784(28x28)\n",
    "n_steps = 28 #셀수\n",
    "n_inputs = 28  #셀당 인풋사이즈\n",
    "n_nuerons = 150  #뉴런출력\n",
    "n_outputs = 10  #확률 사이즈\n",
    "learning_rate = 0.001\n",
    "\n",
    "tf.reset_default_graph()\n",
    "#3차원으로 \n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "#FFNN \n",
    "#셀:27개\n",
    "#states 마지막 셀의 수평으로 전달 되는 값\n",
    "#states는 마지막 셀의 outputs 과 같다.\n",
    "#28개의 셀이 있는데 마지막 1개의 ouput.을 사용한다=>many to one :감정분류 (분류기)\n",
    "#states 의 차수:150x 150\n",
    "#outputs :의 차수: latent time  지연시간을 통해 계산될 셀의 모든 값을 결합 출력 150 * 28 * 150\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units = n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype = tf.float32)\n",
    "\n",
    "#150개의 특징중에 10개만 추출 \n",
    "#dense 입력차수,출력차수만 지정하면 자동으로 바이어스를 만들고 가중치 공간을 확보해서 계산\n",
    "#150 x 150 =>150 x 10 \n",
    "#dense 의 가중치 사이즈= 150x10\n",
    "\n",
    "logits = tf.layers.dense(states, n_outputs)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits) #분류를 위한 미분이 가능한 식으로 바뀜\n",
    "loss = tf.reduce_mean(xentropy) #배치사이즈 를 쓰는 이유 =>평균을 통해 .loss 를 구함\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate) #AdamOptimizer :momentum +propgrad\n",
    "training_op = optimizer.minimize(loss) \n",
    "correct = tf.nn.in_top_k(logits, y, 1)  #가장큰값\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-48-b52a6ff471ea>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-48-b52a6ff471ea>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    cnn ,rnn  모두 ffnn 의 전 단계 (융합)\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "cnn ,rnn  모두 ffnn 의 전 단계 (융합)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-91fe5784da22>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_07\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_07\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_07\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_07\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets('/tmp/data/')\n",
    "X_test=mnist.test.images.reshape((-1,n_steps,n_inputs))\n",
    "Y_test=mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train accuracy: 0.36 test accuracy: 0.36\n",
      "1 train accuracy: 0.38666666 test accuracy: 0.38666666\n",
      "2 train accuracy: 0.44 test accuracy: 0.44\n",
      "3 train accuracy: 0.50666666 test accuracy: 0.50666666\n",
      "4 train accuracy: 0.46666667 test accuracy: 0.46666667\n",
      "5 train accuracy: 0.50666666 test accuracy: 0.50666666\n",
      "6 train accuracy: 0.49333334 test accuracy: 0.49333334\n",
      "7 train accuracy: 0.5133333 test accuracy: 0.5133333\n",
      "8 train accuracy: 0.5133333 test accuracy: 0.5133333\n",
      "9 train accuracy: 0.56666666 test accuracy: 0.56666666\n",
      "10 train accuracy: 0.52 test accuracy: 0.52\n",
      "11 train accuracy: 0.58 test accuracy: 0.58\n",
      "12 train accuracy: 0.50666666 test accuracy: 0.50666666\n",
      "13 train accuracy: 0.48 test accuracy: 0.48\n",
      "14 train accuracy: 0.54 test accuracy: 0.54\n",
      "15 train accuracy: 0.53333336 test accuracy: 0.53333336\n",
      "16 train accuracy: 0.5466667 test accuracy: 0.5466667\n",
      "17 train accuracy: 0.5466667 test accuracy: 0.5466667\n",
      "18 train accuracy: 0.53333336 test accuracy: 0.53333336\n",
      "19 train accuracy: 0.53333336 test accuracy: 0.53333336\n",
      "20 train accuracy: 0.46666667 test accuracy: 0.46666667\n",
      "21 train accuracy: 0.58 test accuracy: 0.58\n",
      "22 train accuracy: 0.56666666 test accuracy: 0.56666666\n",
      "23 train accuracy: 0.6066667 test accuracy: 0.6066667\n",
      "24 train accuracy: 0.58666664 test accuracy: 0.58666664\n",
      "25 train accuracy: 0.58666664 test accuracy: 0.58666664\n",
      "26 train accuracy: 0.62666667 test accuracy: 0.62666667\n",
      "27 train accuracy: 0.58 test accuracy: 0.58\n",
      "28 train accuracy: 0.56 test accuracy: 0.56\n",
      "29 train accuracy: 0.6 test accuracy: 0.6\n",
      "30 train accuracy: 0.58666664 test accuracy: 0.58666664\n",
      "31 train accuracy: 0.50666666 test accuracy: 0.50666666\n",
      "32 train accuracy: 0.6 test accuracy: 0.6\n",
      "33 train accuracy: 0.5933333 test accuracy: 0.5933333\n",
      "34 train accuracy: 0.58 test accuracy: 0.58\n",
      "35 train accuracy: 0.54 test accuracy: 0.54\n",
      "36 train accuracy: 0.62666667 test accuracy: 0.62666667\n",
      "37 train accuracy: 0.53333336 test accuracy: 0.53333336\n",
      "38 train accuracy: 0.5733333 test accuracy: 0.5733333\n",
      "39 train accuracy: 0.62 test accuracy: 0.62\n",
      "40 train accuracy: 0.5933333 test accuracy: 0.5933333\n",
      "41 train accuracy: 0.6066667 test accuracy: 0.6066667\n",
      "42 train accuracy: 0.6333333 test accuracy: 0.6333333\n",
      "43 train accuracy: 0.6533333 test accuracy: 0.6533333\n",
      "44 train accuracy: 0.5933333 test accuracy: 0.5933333\n",
      "45 train accuracy: 0.6 test accuracy: 0.6\n",
      "46 train accuracy: 0.58 test accuracy: 0.58\n",
      "47 train accuracy: 0.5733333 test accuracy: 0.5733333\n",
      "48 train accuracy: 0.6666667 test accuracy: 0.6666667\n",
      "49 train accuracy: 0.5933333 test accuracy: 0.5933333\n",
      "50 train accuracy: 0.5733333 test accuracy: 0.5733333\n",
      "51 train accuracy: 0.6 test accuracy: 0.6\n",
      "52 train accuracy: 0.64 test accuracy: 0.64\n",
      "53 train accuracy: 0.5933333 test accuracy: 0.5933333\n",
      "54 train accuracy: 0.6666667 test accuracy: 0.6666667\n",
      "55 train accuracy: 0.61333334 test accuracy: 0.61333334\n",
      "56 train accuracy: 0.6 test accuracy: 0.6\n",
      "57 train accuracy: 0.5933333 test accuracy: 0.5933333\n",
      "58 train accuracy: 0.62666667 test accuracy: 0.62666667\n",
      "59 train accuracy: 0.6666667 test accuracy: 0.6666667\n",
      "60 train accuracy: 0.66 test accuracy: 0.66\n",
      "61 train accuracy: 0.6066667 test accuracy: 0.6066667\n",
      "62 train accuracy: 0.72 test accuracy: 0.72\n",
      "63 train accuracy: 0.68666667 test accuracy: 0.68666667\n",
      "64 train accuracy: 0.6333333 test accuracy: 0.6333333\n",
      "65 train accuracy: 0.64 test accuracy: 0.64\n",
      "66 train accuracy: 0.6333333 test accuracy: 0.6333333\n",
      "67 train accuracy: 0.67333335 test accuracy: 0.67333335\n",
      "68 train accuracy: 0.73333335 test accuracy: 0.73333335\n",
      "69 train accuracy: 0.68 test accuracy: 0.68\n",
      "70 train accuracy: 0.68666667 test accuracy: 0.68666667\n",
      "71 train accuracy: 0.67333335 test accuracy: 0.67333335\n",
      "72 train accuracy: 0.64 test accuracy: 0.64\n",
      "73 train accuracy: 0.7 test accuracy: 0.7\n",
      "74 train accuracy: 0.6333333 test accuracy: 0.6333333\n",
      "75 train accuracy: 0.68666667 test accuracy: 0.68666667\n",
      "76 train accuracy: 0.8 test accuracy: 0.8\n",
      "77 train accuracy: 0.74 test accuracy: 0.74\n",
      "78 train accuracy: 0.72 test accuracy: 0.72\n",
      "79 train accuracy: 0.6933333 test accuracy: 0.6933333\n",
      "80 train accuracy: 0.68 test accuracy: 0.68\n",
      "81 train accuracy: 0.62 test accuracy: 0.62\n",
      "82 train accuracy: 0.62 test accuracy: 0.62\n",
      "83 train accuracy: 0.6333333 test accuracy: 0.6333333\n",
      "84 train accuracy: 0.68 test accuracy: 0.68\n",
      "85 train accuracy: 0.6933333 test accuracy: 0.6933333\n",
      "86 train accuracy: 0.62666667 test accuracy: 0.62666667\n",
      "87 train accuracy: 0.66 test accuracy: 0.66\n",
      "88 train accuracy: 0.70666665 test accuracy: 0.70666665\n",
      "89 train accuracy: 0.64666665 test accuracy: 0.64666665\n",
      "90 train accuracy: 0.7133333 test accuracy: 0.7133333\n",
      "91 train accuracy: 0.68666667 test accuracy: 0.68666667\n",
      "92 train accuracy: 0.68 test accuracy: 0.68\n",
      "93 train accuracy: 0.76666665 test accuracy: 0.76666665\n",
      "94 train accuracy: 0.6933333 test accuracy: 0.6933333\n",
      "95 train accuracy: 0.6533333 test accuracy: 0.6533333\n",
      "96 train accuracy: 0.6533333 test accuracy: 0.6533333\n",
      "97 train accuracy: 0.68666667 test accuracy: 0.68666667\n",
      "98 train accuracy: 0.7266667 test accuracy: 0.7266667\n",
      "99 train accuracy: 0.62 test accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "n_epochs=100\n",
    "batch_size=150\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):  #60000 만개(테스트)의 데이터150으로 나누고 100씩 \n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch=mnist.train.next_batch(batch_size)\n",
    "            X_batch=X_batch.reshape((-1,n_steps,n_inputs))\n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "            acc_train=accuracy.eval(feed_dict={X:X_batch,y:y_batch})\n",
    "            acc_test=accuracy.eval(feed_dict={X:X_batch,y:y_batch})\n",
    "        print(epoch,\"train accuracy:\",acc_train,\"test accuracy:\",acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-205c80e163bc>:21: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "#BasicRNNCell :기본데이터가 입력\n",
    "#MultiRNNCell :수직으로 레이어 구성\n",
    "#dynamic_rnn : \n",
    "#3층 셀이 28개가 조성:고정사이즈\n",
    "#reset_praph()\n",
    "n_steps = 28 \n",
    "n_inputs = 28  \n",
    "n_nuerons = 150  \n",
    "n_outputs = 10  \n",
    "learning_rate = 0.001\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "n_neurons=100\n",
    "n_layers=3  #3개의 멀티 레이어: 3개의 셀을 생성\n",
    "\n",
    "layers=[tf.contrib.rnn.BasicRNNCell(num_units=n_neurons,activation=tf.nn.relu) for layer in range(n_layers)]\n",
    "\n",
    "#3개의 셀을 조합해서 MultiRNNCell을 만듦\n",
    "multi_layer_cell=tf.contrib.rnn.MultiRNNCell(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001C15F110D48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001C15F110D48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001C15F110D48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001C15F110D48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001C15F110F08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001C15F110F08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001C15F110F08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001C15F110F08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001C15F1107C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001C15F1107C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001C15F1107C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001C15F1107C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001C15F132108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001C15F132108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001C15F132108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001C15F132108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001C15EA32A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001C15EA32A88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001C15EA32A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001C15EA32A88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "#dynamic_rnn :셀로 입력되는 데이터의 개수에 맞추어서 셀을 구성\n",
    "#나는 학교에 간다. static_rnn 동일한 사이즈 :큰것 기준, 작은 것은 padding(자체도 데이터이기 때문에 dynamic_rnn를 씀)\n",
    "#입력 사이즈 변동=가중치 조절 =>나가는 특징은 일치\n",
    "outputs,states=tf.nn.dynamic_rnn(multi_layer_cell,X,dtype=tf.float32)\n",
    "\n",
    "#states가 몇개 발생하는가? 3(멀티레이어)x 150x 100\n",
    "states_concat=tf.concat(axis=1, values=states)  #150 x 300\n",
    "logits=tf.layers.dense(states_concat,n_outputs)  #가중치: 300 X 10 , logit:150x 10 =확률값\n",
    "\n",
    "xentropy=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "#softmax을 거치면서 원핫 인코딩 * log (예측값)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate) #AdamOptimizer :momentum +propgrad\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "training_op = optimizer.minimize(loss) \n",
    "correct = tf.nn.in_top_k(logits, y, 1)  #가장큰값\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train accuracy: 0.9533333 test accuracy: 0.9533333\n",
      "1 train accuracy: 0.9533333 test accuracy: 0.9533333\n",
      "2 train accuracy: 0.99333334 test accuracy: 0.99333334\n",
      "3 train accuracy: 0.97333336 test accuracy: 0.97333336\n",
      "4 train accuracy: 0.99333334 test accuracy: 0.99333334\n",
      "5 train accuracy: 0.99333334 test accuracy: 0.99333334\n",
      "6 train accuracy: 0.9866667 test accuracy: 0.9866667\n",
      "7 train accuracy: 0.98 test accuracy: 0.98\n",
      "8 train accuracy: 0.98 test accuracy: 0.98\n",
      "9 train accuracy: 0.9866667 test accuracy: 0.9866667\n"
     ]
    }
   ],
   "source": [
    "n_epochs=10\n",
    "batch_size=150\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):  #60000 만개(테스트)의 데이터150으로 나누고 100씩 \n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch=mnist.train.next_batch(batch_size)\n",
    "            X_batch=X_batch.reshape((-1,n_steps,n_inputs))\n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "            acc_train=accuracy.eval(feed_dict={X:X_batch,y:y_batch})\n",
    "            acc_test=accuracy.eval(feed_dict={X:X_batch,y:y_batch})\n",
    "        print(epoch,\"train accuracy:\",acc_train,\"test accuracy:\",acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ICT01_07\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_07\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000016926E85C48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000016926E85C48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000016926E85C48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000016926E85C48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-35-d6c030937705>:22: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "learning_rate = 0.001\n",
    "total_epoch = 10\n",
    "batch_size = 128\n",
    "n_input =28\n",
    "n_step = 28\n",
    "n_hidden = 128\n",
    "n_class = 10                          #세로   #가로\n",
    "X = tf.placeholder(tf.float32, [None, n_step, n_input]) #128 X 28 x28\n",
    "Y = tf.placeholder(tf.float32, [None, n_class]) #128 x10\n",
    "W = tf.Variable(tf.random_normal([n_hidden, n_class])) #n_hidden : 노드(특징추출하는 레이어수) 128 x 10 (0~9 까지)\n",
    "b = tf.Variable(tf.random_normal([n_class])) #10\n",
    "\n",
    "#28 x 128 사이즈의 가중치\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden) #neurons :128특징 :n_hidden : 노드(특징추출하는 레이어수) 128 x 10 (0~9 까지)  \n",
    "\n",
    "#cell 수: 28 \n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype = tf.float32)\n",
    "\n",
    "#outputs: 128 x 28 x128 , states:128 x 128 \n",
    "outputs = tf.transpose(outputs, [1,0,2])  #28x 128x 128 \n",
    "\n",
    "#셀로 \n",
    "outputs = outputs[-1]  #맨 마지막 셀 : ??\n",
    "model = tf.matmul(outputs, W) + b\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 Avg. cost =  0.516\n",
      "Epoch:  0002 Avg. cost =  0.241\n",
      "Epoch:  0003 Avg. cost =  0.193\n",
      "Epoch:  0004 Avg. cost =  0.153\n",
      "Epoch:  0005 Avg. cost =  0.142\n",
      "Epoch:  0006 Avg. cost =  0.131\n",
      "Epoch:  0007 Avg. cost =  0.124\n",
      "Epoch:  0008 Avg. cost =  0.118\n",
      "Epoch:  0009 Avg. cost =  0.112\n",
      "Epoch:  0010 Avg. cost =  0.099\n",
      "최적화 완료\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "for epoch in range(total_epoch):\n",
    "    total_cost =0\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        #이미지 사이즈로 리쉐입\n",
    "        batch_xs = batch_xs.reshape((batch_size, n_step, n_input))\n",
    "        #python 이 계산한 마지막 결과가 저장되는 것이 _\n",
    "        _, cost_val = sess.run([optimizer, cost], feed_dict = {X: batch_xs, Y: batch_ys})\n",
    "        total_cost += cost_val\n",
    "    print(\"Epoch: \", '%04d' % (epoch + 1), 'Avg. cost = ', '{:.3f}'.format(total_cost/total_batch))\n",
    "print(\"최적화 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#문제\n",
    "1.테스트 데이터를 이용하여 테스트하는 회로를 구성하시오\n",
    "2. 3개의 셀을 갖는 multi-layer cell 로 수정하시오\n",
    "\n",
    "#3개의 셀로 멀티레이어 생성해도 output 은 하나의 셀일 경우와 동일\n",
    "#state에서는 3개의 레이어 마다 생성\n",
    "\n",
    "\n",
    "n_layers=3  #3개의 멀티 레이어: 3개의 셀을 생성\n",
    "layers=[tf.contrib.rnn.BasicRNNCell(num_units=n_neurons,activation=tf.nn.relu) for layer in range(n_layers)]\n",
    "multi_layer_cell=tf.contrib.rnn.MultiRNNCell(layers)\n",
    "outputs,states=tf.nn.dynamic_rnn(multi_layer_cell,X,dtype=tf.float32)\n",
    "........#앞에서한 예제를 보면 됨\n",
    "\n",
    "\n",
    "#with 없이 세션을 열었기 때문에 바로 코딩을 해도 돌아간다 (앞의 예제에서 했음)\n",
    "is_correct=tf.equal(tf.argmax(model,1),tf.argmax(Y,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
    "test_batch_size=len(mnist.test.images)\n",
    "test_xs=mnist.test.images.reshape(test_batch_size,n_step,n_input)\n",
    "test_ys=mnist.test.labels\n",
    "print('정확도:',sess.run(accuracy,feed_dict:{X:test_xs,Y:test_ys})) #정확도 :0.977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력데이터의 shape (2, 3, 1)\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000016926901D08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000016926901D08>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000016926901D08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000016926901D08>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "rnn 이 출력하는 outputs의 의미 (2, 3, 100)\n"
     ]
    }
   ],
   "source": [
    "#질문 !!\n",
    "import numpy as np\n",
    "values231=np.array([[[1],[2],[3]],[[2],[3],[4]]])\n",
    "print('입력데이터의 shape',values231.shape) #2x3x1\n",
    "tf.reset_default_graph()\n",
    "tf.values231=tf.constant(values231,dtype=tf.float32) \n",
    "#1 x 100  :가중치가 4개 이기때문 , \n",
    "#LSTMCell 4개를 학습해야하므로 \n",
    "\n",
    "lstm_cell=tf.contrib.rnn.LSTMCell(num_units=100) #뉴론\n",
    "\n",
    "#rnn 모델은 동일 :망과 망을 연결할때 (번역망 : 한글, 영어)\n",
    "#ratent time: 지연시간\n",
    "outputs,state=tf.nn.dynamic_rnn(cell=lstm_cell,dtype=tf.float32,inputs=tf.values231)\n",
    "print(state.c.shape) #2 100   #??\n",
    "print(state.h.shape)  #2 100\n",
    "\n",
    "print('rnn 이 출력하는 outputs의 의미',outputs.shape)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    output_run,state_run=sess.run([outputs,state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const:0' shape=(2, 3, 1) dtype=float32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf   \n",
    "import numpy as np\n",
    "values=tf.constant(np.array([[[1],[2],[3]],[[2],[3],[4]]]), dtype=tf.float32)\n",
    "print(values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001C11D7A8B88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001C11D7A8B88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001C11D7A8B88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001C11D7A8B88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001C1620210C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001C1620210C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001C1620210C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001C1620210C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "(2, 3, 100)\n",
      "(2, 3, 100)\n",
      "(2, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "#질문!\n",
    "\n",
    "import tensorflow as tf    \n",
    "tf.reset_default_graph()\n",
    "values=tf.constant(np.array([[[1],[2],[3]],[[2],[3],[4]]]), dtype=tf.float32)\n",
    "lstm_cell_fw=tf.contrib.rnn.LSTMCell(100)  #??\n",
    "lstm_cell_bw=tf.contrib.rnn.LSTMCell(100)\n",
    "#Multi cell: 셀에서\n",
    "#양방향 LSTM\n",
    "(output_fw,output_bw),(output_state_fw,output_state_bw)=tf.nn.bidirectional_dynamic_rnn(cell_fw=lstm_cell_fw, cell_bw=lstm_cell_bw,\n",
    "                                                                                       inputs=values,dtype=tf.float32)\n",
    "print(output_fw.shape)\n",
    "print(output_bw.shape)\n",
    "print(values.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 4)\n",
      "array([[[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]]], dtype=float32)\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001C11E11C148>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001C11E11C148>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001C11E11C148>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001C11E11C148>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "array([[[-0.2296784 , -0.5557229 ],\n",
      "        [ 0.25059763, -0.03292963],\n",
      "        [ 0.2394907 , -0.20342518],\n",
      "        [ 0.24244171, -0.29622963],\n",
      "        [-0.07254155, -0.18487242]]], dtype=float32)\n",
      "(1, 5, 2)\n",
      "(1, 2)\n",
      "array([[-0.07254155, -0.18487242]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#embedding 한다..고 함\n",
    "import pprint  #데이터 형태대로 찍을수 있게 하는거\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "pp=pprint.PrettyPrinter(indent=4)\n",
    "sess=tf.InteractiveSession() \n",
    "h=[1,0,0,0] #단어를 원핫인코딩: 수치화 \n",
    "e=[0,1,0,0]\n",
    "l=[0,0,1,0]\n",
    "o=[0,0,0,1]\n",
    "#h=[1,0,0,0]\n",
    "#e=[0,1,0,0]\n",
    "#l=[0,0,1,0]\n",
    "#l=[0,0,1,0]\n",
    "#o=[0,0,0,1]\n",
    "\n",
    "#변수공유를 위해 지정\n",
    "with tf.variable_scope('five_sequences') as scope:\n",
    "    hidden_size=2  #4개 에서 2개의 특징으로 벡터화 된다.\n",
    "    cell=tf.contrib.rnn.BasicRNNCell(num_units=hidden_size)\n",
    "    x_data=np.array([[h,e,l,l,o]],dtype=np.float32)\n",
    "    print(x_data.shape) #1, 5, 4 =데이터가 한개를 3차원으로 만들어주려고 \n",
    "    pp.pprint(x_data)\n",
    "    #셀의 개수:5\n",
    "    #셀당 입력데이터는4\n",
    "    #셀당 가중치는 4 x 2\n",
    "    outputs,states=tf.nn.dynamic_rnn(cell,x_data,dtype=tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())\n",
    "    print(outputs.shape)  #1 5 2 \n",
    "    print(states.shape)   # 1(데이터가 한개가 들어갔으니깐),  2  =>[[0.5307638, 0.6647075]]\n",
    "    pp.pprint(states.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "char_arr=['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "num_dic={n:i for i, n in enumerate(char_arr)}#숫자를 자동으로 만들어줌(인덱스처럼....생성,enumerate 사용시는 i, n 처럼 두개필요)\n",
    "dic_len=len(num_dic) #26 개 \n",
    "\n",
    "#a : 0, b:1 ... 글자에 해당되는 것을 숫자로 줌 \n",
    "#rule base=>자동 툴 =>가중치만 이용\n",
    "seq_data=['word','wood','deep','dive','cold','cool','load','love','kiss','kind']\n",
    "\n",
    "#10x3 (세번째 음절 까지만 보므로)  \n",
    "#10x1 =target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#26 x 26 행렬\n",
    "#10000000000000000000000000000000  a가 0번 이므로 0이 1이 되는 것\n",
    "#01000000000000000000000000000000  b가 1번 이므로 01이 되는 것\n",
    "#00100000000000000000000000000000  c가 2번 이므로 001이 되는 것\n",
    "\n",
    "def make_batch(seq_data): #자동으로 문자를 원핫인코딩\n",
    "    input_batch=[]\n",
    "    target_batch=[]\n",
    "    for seq in seq_data: #첫번째로 word가 들어가고 \n",
    "        input=[num_dic[n] for n in seq[:-1]]  #n 이 w=22번 /n 에 o=14, 마지막은 안함\n",
    "        target=num_dic[seq[-1]] #d= 3\n",
    "        input_batch.append(np.eye(dic_len)[input]) #eye 가 자동으로 행렬을 만들어주는 함수.. ex) 22번이 1이 되는것을 찾아서...\n",
    "        target_batch.append(target)\n",
    "    return input_batch,target_batch\n",
    "\n",
    "#input 에는 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01\n",
    "n_hidden=128 #가중치를 정하는데 도움을 주는 애\n",
    "total_epoch=30 #30번이돌아감\n",
    "n_step=3 #3번학습할거라서??\n",
    "n_input=n_class=dic_len  #26 개 \n",
    "\n",
    "X=tf.placeholder(tf.float32,[None,n_step,n_input]) #10 ,3, 26\n",
    "Y=tf.placeholder(tf.int32,[None]) #10 ,26\n",
    "#ffnn\n",
    "W=tf.Variable(tf.random_normal([n_hidden,n_class])) #128 x 26\n",
    "b=tf.Variable(tf.random_normal([n_class]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001C162010408>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001C162010408>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001C162010408>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x000001C162010408>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000001C12D7229C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000001C12D7229C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000001C12D7229C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000001C12D7229C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000001C11D685348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000001C11D685348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000001C11D685348>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000001C11D685348>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "cell1=tf.nn.rnn_cell.BasicLSTMCell(n_hidden) #특성을 128개로 \n",
    "cell1=tf.nn.rnn_cell.DropoutWrapper(cell1,output_keep_prob=0.5,seed=10)\n",
    "cell2=tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "\n",
    "#2레이어로 구성된 멀티셀\n",
    "multi_cell=tf.nn.rnn_cell.MultiRNNCell([cell1,cell2])\n",
    "outputs,states=tf.nn.dynamic_rnn(multi_cell,X,dtype=tf.float32)  #??\n",
    "\n",
    "#outputs 10 3 128\n",
    "#states 10 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs=tf.transpose(outputs,[1,0,2]) #3 10 128 \n",
    "outputs=outputs[-1] #맨뒤의 셀뺌 10 128   \n",
    "model=tf.matmul(outputs,W)+b #비선형회귀방식\n",
    "#분류에서의 엔트로피\n",
    "cost=tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model,labels=Y))\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0001 cost = 4.553142\n",
      "Epoch : 0002 cost = 3.413800\n",
      "Epoch : 0003 cost = 1.858945\n",
      "Epoch : 0004 cost = 1.903587\n",
      "Epoch : 0005 cost = 0.831649\n",
      "Epoch : 0006 cost = 1.625600\n",
      "Epoch : 0007 cost = 0.990520\n",
      "Epoch : 0008 cost = 0.775356\n",
      "Epoch : 0009 cost = 0.500011\n",
      "Epoch : 0010 cost = 0.731038\n",
      "Epoch : 0011 cost = 0.483169\n",
      "Epoch : 0012 cost = 0.282181\n",
      "Epoch : 0013 cost = 0.283094\n",
      "Epoch : 0014 cost = 0.459404\n",
      "Epoch : 0015 cost = 0.326421\n",
      "Epoch : 0016 cost = 0.209920\n",
      "Epoch : 0017 cost = 0.171105\n",
      "Epoch : 0018 cost = 0.145702\n",
      "Epoch : 0019 cost = 0.210732\n",
      "Epoch : 0020 cost = 0.162402\n",
      "Epoch : 0021 cost = 0.048038\n",
      "Epoch : 0022 cost = 0.113698\n",
      "Epoch : 0023 cost = 0.065581\n",
      "Epoch : 0024 cost = 0.128191\n",
      "Epoch : 0025 cost = 0.070206\n",
      "Epoch : 0026 cost = 0.031214\n",
      "Epoch : 0027 cost = 0.042788\n",
      "Epoch : 0028 cost = 0.054056\n",
      "Epoch : 0029 cost = 0.026347\n",
      "Epoch : 0030 cost = 0.026552\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "input_batch , target_batch = make_batch(seq_data) # 단어데이터\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    _, loss = sess.run([optimizer, cost], feed_dict={X:input_batch, Y:target_batch})\n",
    "    print('Epoch : %04d'%(epoch+1), 'cost = {:.6f}'.format(loss)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=tf.cast(tf.argmax(model,1),tf.int32) #실수형을 정수형으로 \n",
    "prediction_check=tf.equal(prediction,Y)\n",
    "accuracy=tf.reduce_mean(tf.cast(prediction_check,tf.float32)) #int32 ,float32로 하면 계산안될때가있당\n",
    "input_batch,target_batch=make_batch(seq_data)\n",
    "predict,accuracy_val=sess.run([prediction,accuracy],feed_dict={X:input_batch, Y:target_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#문제:predict 한 결과를 출력하고 accuracy를 출력하시오\n",
    "#입력단어와 예측 결과를 나란히 출력해 보시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측된 결과  [ 3  3 15  4  3 11  3  4 18  3]\n",
      "accuracy 1.0\n",
      "입력값: ['wor ', 'woo ', 'dee ', 'div ', 'col ', 'coo ', 'loa ', 'lov ', 'kis ', 'kin ']\n",
      "예측값: ['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss', 'kind']\n"
     ]
    }
   ],
   "source": [
    "print('예측된 결과 ', predict)\n",
    "print('accuracy',accuracy_val)\n",
    "\n",
    "predict_words=[]\n",
    "\n",
    "#단어가 순서대로 입력,순서대로 예측\n",
    "for idx, val in enumerate(seq_data):\n",
    "    last_char=char_arr[predict[idx]]#인덱스가 단어 매핑\n",
    "    predict_words.append(val[:3]+last_char) #세번째 음절까지 (마지막음절은 뺐음 왜?)\n",
    "print('입력값:',[w[:3]+ ' ' for w in seq_data])\n",
    "print('예측값:',predict_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
